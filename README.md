<br><br>



#  [Unsloth]() â€” Fast Fine-tuning & Reinforcement Learning for LLMs


<br><br>

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)(#license)
[![Python](https://img.shields.io/badge/Python-â‰¤3.13-blue)](#installation)
[![Stars](https://img.shields.io/github/stars/unslothai/unsloth?style=social)](https://github.com/unslothai/unsloth)

<br><br>




> [!TIP]
>
> * Fine-tuning & Reinforcement Learning for modern LLMs with **up to 2Ã— faster training** and **70% less VRAM use**.
>




<br><br>




##  Table of Contents

* [ Get Started](#-get-started)
* [Fine-tuning Guide](#-fine-tuning-guide)
* [ Model Selection](#-model-selection)
* [ Tutorials](#-tutorials)
* [FAQ](#-faq)
* [Installation](#-installation)
* [ Dataset Guide](#-dataset-guide)
* [ Requirements](#-requirements)
* [ Inference & Deployment](#-inference--deployment)
* [ LoRA Hyperparameters](#-lora-hyperparameters)
* [âš¡ Quickstart â€” CLI](#-quickstart--cli)
* [ Mistral 3 Quickstart](#-mistral-3-quickstart)
* [ Unsloth News](#-unsloth-news)
* [ Performance Benchmarks](#-performance-benchmarks)
* [Citation](#-citation)
* [License](#-license)


<br><br>


<br><br>

## Get Started

**Beginner? Start here!**
Perguntas mais comuns antes do seu primeiro fine-tune.

ğŸ‘‰ Pergunte tambÃ©m na comunidade: r/unsloth (Reddit)


#


## Fine-tuning Guide

Aprenda como treinar modelos passo a passo.
Inclui: SFT, QLoRA, FP8 training e GRPO.

<br><br>

## Model Selection

* Instruct vs Base
* Tamanho ideal do dataset
* Quando usar RAG vs Fine-tuning

<br><br>


## ğŸ“˜ Tutorials

* Fine-tuning DeepSeek
* ParametrizaÃ§Ã£o para Gemma 3
* Como rodar modelos localmente, via Ollama, GGUF, SGLang, vLLM

---

# ğŸ¤” FAQ

* Quando fine-tunar?
* DiferenÃ§a entre SFT, DPO, GRPO
* Como evitar OOM (out-of-memory)?

---

# ğŸ“¥ Installation

## Linux / WSL

```bash
pip install unsloth
```

## Windows

*Requer PyTorch previamente instalado.*

Guia completo: Windows Guide.

## Docker

```bash
docker run -d -e JUPYTER_PASSWORD="mypassword" \
  -p 8888:8888 -p 2222:22 \
  -v $(pwd)/work:/workspace/work \
  --gpus all \
  unsloth/unsloth
```

---

# ğŸ“ˆ Dataset Guide

* Como organizar dataset SFT
* DPO vs SFT formats
* Captura de dados
* Boas prÃ¡ticas

---

# ğŸ›  Requirements

CompatÃ­vel com:

* NVIDIA GPUs (2018+)
* AMD
* Intel
* CUDA Capability â‰¥ 7.0

---

# ğŸ–¥ Inference & Deployment

* Export GGUF
* Roda via llama.cpp
* Roda via vLLM, SGLang, Ollama
* Salvamento de checkpoints

---

# ğŸ§  LoRA Hyperparameters

Comportamento dos parÃ¢metros:
r, alpha, target_modules, dropout, RSLORA, LoftQ, etc.

---

# âš¡ Quickstart â€” CLI

Exemplo de fine-tuning **gpt-oss-20b**:

```python
from unsloth import FastLanguageModel, FastModel
from trl import SFTTrainer, SFTConfig
from datasets import load_dataset

max_seq_length = 2048
dataset = load_dataset("json", data_files={"train": ".../unified_chip2.jsonl"}, split="train")

model, tokenizer = FastModel.from_pretrained(
    "unsloth/gpt-oss-20b",
    max_seq_length=max_seq_length,
    load_in_4bit=True,
)

model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    target_modules=["q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj","down_proj"],
    lora_alpha=16,
    lora_dropout=0,
)

trainer = SFTTrainer(
    model=model,
    train_dataset=dataset,
    tokenizer=tokenizer,
    args=SFTConfig(
        max_seq_length=max_seq_length,
        per_device_train_batch_size=2,
        gradient_accumulation_steps=4,
        max_steps=60,
        logging_steps=1,
    ),
)

trainer.train()
```

---

# ğŸŒŸ Mistral 3 Quickstart

> **Nova seÃ§Ã£o solicitada â€” estilo idÃªntico ao README oficial**

Treine **Mistral 3** (7B/8B/22B/large) usando QLoRA ou full-finetuning.

## â–¶ï¸ InstalaÃ§Ã£o

```bash
pip install unsloth
```

## â–¶ï¸ Carregar modelo Mistral 3

```python
from unsloth import FastModel, FastLanguageModel

model, tokenizer = FastModel.from_pretrained(
    model_name="unsloth/mistral-3-8b",
    max_seq_length=4096,
    load_in_4bit=True,
)
```

## â–¶ï¸ Aplicar LoRA otimizado

```python
model = FastLanguageModel.get_peft_model(
    model,
    r=32,
    lora_alpha=32,
    lora_dropout=0,
    target_modules=["q_proj","k_proj","v_proj","o_proj","gate_proj","up_proj","down_proj"],
)
```

## â–¶ï¸ Treinar

```python
from trl import SFTTrainer, SFTConfig

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    args=SFTConfig(
        output_dir="mistral3-output",
        per_device_train_batch_size=2,
        gradient_accumulation_steps=4,
        max_steps=120,
        logging_steps=1,
    ),
)

trainer.train()
```

## â–¶ï¸ Exportar para GGUF

```python
model.save_pretrained("mistral3-gguf")
```

---

# ğŸ¦¥ Unsloth News

* FP8 Reinforcement Learning
* DeepSeek OCR Fine-tuning
* Novo Docker super otimizado
* Suporte completo para TTS, Vision, GRPO, GSPO, DPO, ORPOâ€¦

---

# ğŸ¥‡ Performance Benchmarks

ComparaÃ§Ã£o Unsloth vs HuggingFace (FA2):

* **2Ã— mais rÃ¡pido**
* **AtÃ© 75% menos VRAM**
* **Longest context: 340k tokens** (para GPUs 80GB)

---

# ğŸ“œ Citation

```bibtex
@software{unsloth,
  author = {Daniel Han, Michael Han and Unsloth team},
  title = {Unsloth},
  url = {http://github.com/unslothai/unsloth},
  year = {2023}
}
```


<br><br>


## ğŸ’Œ [Let the data flow... Ping Me !](mailto:fabicampanari@proton.me)

<br>


#### <p align="center">  ğŸ›¸à¹‹ My Contacts [Hub](https://linktr.ee/fabianacampanari)


<br>

### <p align="center"> <img src="https://github.com/user-attachments/assets/517fc573-7607-4c5d-82a7-38383cc0537d" />


<br><br>

<p align="center">  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âŠ¹ğŸ”­à¹‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

<!--
<p align="center">  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ›¸à¹‹*à©ˆâœ©* ğŸ”­*à©ˆâ‚Š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-->

<br>

<p align="center"> â£â¢â¤ <a href="#top">Back to Top </a>
  

  
#
 
##### <p align="center">Copyright 2025 Mindful-AI-Assistants. Code released under the  [Apavhe Licencve.](https://github.com/Mindful-AI-Assistants/CDIA-Entrepreneurship-Soft-Skills-PUC-SP/blob/21961c2693169d461c6e05900e3d25e28a292297/LICENSE)
