<br>
 
 \[[ğŸ‡§ğŸ‡· PortuguÃªs](README.pt_BR.md)\] \[**[ğŸ‡ºğŸ‡¸ English](README.md

<br>


# Fine-tuning Ministral-3 with Unsloth â€” Complete Guide

<br>



Este repositÃ³rio fornece um ambiente completo, rÃ¡pido e moderno para fine-tuning, inferÃªncia, curadoria de dados e exportaÃ§Ã£o de modelos Ministral-3, Llama, Qwen, Gemma, DeepSeek e variantes, utilizando o ecossistema Unsloth.

Inclui notebooks prontos, scripts de treino, exemplos de datasets, Docker, exportaÃ§Ã£o para GGUF/Ollama/vLLM e suporte a Reinforcement Learning (GRPO, DPO, ORPO, KTO).


<br><br>


## IndÃ­ce

- [IntroduÃ§Ã£o](#introduÃ§Ã£o)
- [Features](#features)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
  - [Pip](#pip)
  - [Conda](#conda)
  - [Docker](#docker)
  - [Windows](#windows)
  - [Google Colab](#google-colab)
- [Guia de Fine-tuning](#guia-de-fine-tuning)
  - [Escolha de Modelo](#escolha-de-modelo)
  - [Estrutura de Dataset](#estrutura-de-dataset)
  - [HiperparÃ¢metros LoRA](#hiperparÃ¢metros-lora)
  - [Vision Fine-tuning](#vision-fine-tuning)
- [Ministral-3 Quickstart](#ministral-3-quickstart)
- [Notebooks](#notebooks)
- [Scripts](#scripts)
- [Estrutura do RepositÃ³rio](#estrutura-do-repositÃ³rio)
- [Deployment & Export](#deployment--export)
  - [Ollama](#ollama)
  - [vLLM](#vllm)
  - [GGUF](#gguf)
- [Troubleshooting](#troubleshooting)
- [Comunidade & Suporte](#comunidade--suporte)
- [License](#license)

  <br><br>
