<br>
 
 \[[üáßüá∑ Portugu√™s](README.pt_BR.md)\] \[**[üá∫üá∏ English](README.md)**\]

<br><br>


# <p align="center"> Fine-tuning Ministral-3 with [Unsloth]() üî• Guia Completo
### <p align="center"> Treino acelerado, otimizado e barato usando Unsloth + Ministral-3.

<br><br>



Este reposit√≥rio fornece um ambiente completo, r√°pido e moderno para fine-tuning, infer√™ncia, curadoria de dados e exporta√ß√£o de modelos Ministral-3, Llama, Qwen, Gemma, DeepSeek e variantes, utilizando o ecossistema Unsloth.

Inclui notebooks prontos, scripts de treino, exemplos de datasets, Docker, exporta√ß√£o para GGUF/Ollama/vLLM e suporte a Reinforcement Learning (GRPO, DPO, ORPO, KTO).



<br><br><br>



### <p align="center"> [![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](#license) [![Sponsor Mindful AI Assistants](https://img.shields.io/badge/Sponsor-Mindful%20AI%20%20Assistants-brightgreen?logo=GitHub)](https://github.com/sponsors/Mindful-AI-Assistants) [![Python](https://img.shields.io/badge/Python-‚â§3.13-blue)](#installation)


<br><br><br>



> [!NOTE]
>
> [-]()  Ambiente completo de fine-tuning para LLMs usando Unsloth, incluindo <br>
> [-]()  Ministral 3, Qwen, Llama, DeepSeek, Gemma, RL, Vision, exporta√ß√£o GGUF e deployment em produ√ß√£o. <br>
> [-]()  Fonte: [Unsloth ‚Äì Instala√ß√£o & Atualiza√ß√£o](https://docs.unsloth.ai/get-started/install-and-update)  <br> <br>

<br><br>


## [Inclui]():

<br>

[-]() Jupyter notebooks

[-]() Scripts de treinamento, avalia√ß√£o e infer√™ncia

[-]() Exemplos de datasets

[-]() üê≥ Imagens Docker

[-]() Suporte completo ao Unsloth

[-]() üî• Quickstart do Ministral 3




> [!TIP]
>
> * **Fine-tuning & Reinforcement Learning** para LLMs modernos com **at√© 2√ó mais velocidade de treino** e **70% menos uso de VRAM**. <br>
> * **Ambiente completo de fine-tuning** para LLMs usando **Unsloth**, incluindo <br>
> * **Ministral 3**, **Qwen**, **Llama**, **DeepSeek**, **Gemma**, RL, Vision, exporta√ß√£o GGUF e deployment em produ√ß√£o. <br>
>  <br>
>  

<br><br><br>



## Ind√≠ce

- [Introdu√ß√£o](#introdu√ß√£o)
- [Features](#features)
- [Instala√ß√£o](#instala√ß√£o)
  - [Pip](#pip)
  - [Conda](#conda)
  - [Docker](#docker)
  - [Windows](#windows)
  - [Google Colab](#google-colab)
- [Guia de Fine-tuning](#guia-de-fine-tuning)
  - [Escolha de Modelo](#escolha-de-modelo)
  - [Estrutura de Dataset](#estrutura-de-dataset)
  - [Hiperpar√¢metros LoRA](#hiperpar√¢metros-lora)
  - [Vision Fine-tuning](#vision-fine-tuning)
- [Ministral-3 Quickstart](#ministral-3-quickstart)
- [Notebooks](#notebooks)
- [Scripts](#scripts)
- [Estrutura do Reposit√≥rio](#estrutura-do-reposit√≥rio)
- [Deployment & Export](#deployment--export)
  - [Ollama](#ollama)
  - [vLLM](#vllm)
  - [GGUF](#gguf)
- [Troubleshooting](#troubleshooting)
- [Comunidade & Suporte](#comunidade--suporte)
- [License](#license)


<br><br>


## [Introdu√ß√£o]()


Este reposit√≥rio consolida um ambiente robusto e padronizado para:

* **Fine-tuning eficiente com LoRA/QLoRA**
* **Aprendizado por Refor√ßo (GRPO, DPO, ORPO, KTO)**
* **Treinamento em Vis√£o (VLMs)**
* **Exporta√ß√£o para GGUF e deployment em CPU/GPU**
* **Infer√™ncia otimizada com Unsloth e vLLM**
* **Ambiente de desenvolvimento reprodut√≠vel (Docker + Conda)**


<br><br>

## [Suporte completo para:]()

* **Ministral-3 (todos os tamanhos)**
* Llama 3.x
* Qwen 2.5 / 3 / VL
* Gemma 3
* DeepSeek V3 / R1
* Phi 3
* Vision LLMs


<br><br>

##  [Features]()


* ‚ö° *At√© 2√ó mais r√°pido* que frameworks tradicionais
*  *70% menos VRAM* com QLoRA
*  Suporte completo para **Fine-tuning em Vis√£o**
*  Suporte para **RL (GRPO / DPO / ORPO / KTO)**
*  *Contexto ultra-longo* (at√© 500K tokens)
*  Exporta√ß√£o para **GGUF**, **Ollama**, **vLLM**, **safetensors**
*  Docker + scripts padronizados
*  Notebooks para Colab / uso local
*  CPU, CUDA 11.8 / 12.1, AMD ROCm



<br><br>


## [Instala√ß√£o]()

###  [Pip Install]()

<br>

```bash
pip install unsloth
```

<br><br>

### üêç [Conda Install]()

<br>

```bash
conda create --name unsloth_env python=3.11 -y
conda activate unsloth_env
pip install unsloth
```

<br><br>

### üê≥ [Docker]()

<br>

```bash
docker pull unslothai/unsloth:latest
```

<br><br>

### [Suporte Windows]()

<br>

‚úî Via WSL2 (recomendado)

‚úî CUDA 12.1

‚úî Apenas CPU


<br><br>


##  [Google Colab]()

<br>

Notebooks oficiais:
https://docs.unsloth.ai/get-started/beginner-start-here


<br>

[Instala√ß√£o r√°pida:]()

<br>

```bash
!pip install unsloth
```

<br><br>

##  [Guia de Fine-tuning]()


###  [Qual modelo escolher ?]()

<br>

| [Tarefa]()                | Modelo recomendado |
| --------------------- | ------------------ |
| [Chat / Agentes]()        | Instruct           |
| [Racioc√≠nio]()            | Base               |
| [Dataset pequeno (<3k)]() | Instruct           |
| [Dataset grande (>20k)]() | Base               |



<br><br>


## [Estrutura do Dataset]()

### [Formato padr√£o (JSONL):]()

<br>

```json
{
  "messages": [
    {"role": "user", "content": "Ol√°"},
    {"role": "assistant", "content": "Oi! Como posso ajudar?"}
  ]
}
```

<br><br>

## [Hiperpar√¢metros LoRA]()

### [Recomenda√ß√£o inicial:]()

<br>

```√¨ni
r = 16
alpha = 32
dropout = 0.05
target_modules = ["q_proj", "v_proj", "k_proj", "o_proj"]
```

<br><br>


## [Vision Fine-tuning]()

### [Suporte para:]()

<br>

* Ministral-3 Vision

* Qwen-VL

* Gemma Vision


<br><br>


## üî• [Ministral-3 Quickstart]()

###  [Exemplos de modelos suportados]()

<br>

* Ministral-3 Small

* Ministral-3 Medium

* Ministral-3 14B (cabe no Colab Free com QLoRA)


<br><br>

## [Notebook oficial do repo]()


```bash
notebooks/ministral3_finetune.ipynb
```

<br><br>
