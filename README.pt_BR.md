<br>
 
 \[[üáßüá∑ Portugu√™s](README.pt_BR.md)\] \[**[üá∫üá∏ English](README.md

<br><br>


# <p align="center"> Fine-tuning Ministral-3 with [Unsloth]() üî• Guia Completo
### <p align="center"> Treino acelerado, otimizado e barato usando Unsloth + Ministral-3.

<br><br>



Este reposit√≥rio fornece um ambiente completo, r√°pido e moderno para fine-tuning, infer√™ncia, curadoria de dados e exporta√ß√£o de modelos Ministral-3, Llama, Qwen, Gemma, DeepSeek e variantes, utilizando o ecossistema Unsloth.

Inclui notebooks prontos, scripts de treino, exemplos de datasets, Docker, exporta√ß√£o para GGUF/Ollama/vLLM e suporte a Reinforcement Learning (GRPO, DPO, ORPO, KTO).



<br><br><br>



### <p align="center"> [![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](#license) [![Sponsor Mindful AI Assistants](https://img.shields.io/badge/Sponsor-Mindful%20AI%20%20Assistants-brightgreen?logo=GitHub)](https://github.com/sponsors/Mindful-AI-Assistants) [![Python](https://img.shields.io/badge/Python-‚â§3.13-blue)](#installation)


<br><br><br>



> [!NOTE]
>
> [-]()  Ambiente completo de fine-tuning para LLMs usando Unsloth, incluindo <br>
> [-]()  Ministral 3, Qwen, Llama, DeepSeek, Gemma, RL, Vision, exporta√ß√£o GGUF e deployment em produ√ß√£o. <br>
> [-]()  Fonte: [Unsloth ‚Äì Instala√ß√£o & Atualiza√ß√£o](https://docs.unsloth.ai/get-started/install-and-update)  <br> <br>

<br><br>


## [Inclui]():

<br>

[-]() Jupyter notebooks

[-]() Scripts de treinamento, avalia√ß√£o e infer√™ncia

[-]() Exemplos de datasets

[-]() üê≥ Imagens Docker

[-]() Suporte completo ao Unsloth

[-]() üî• Quickstart do Ministral 3




> [!TIP]
>
> * **Fine-tuning & Reinforcement Learning** para LLMs modernos com **at√© 2√ó mais velocidade de treino** e **70% menos uso de VRAM**. <br>
> * **Ambiente completo de fine-tuning** para LLMs usando **Unsloth**, incluindo <br>
> * **Ministral 3**, **Qwen**, **Llama**, **DeepSeek**, **Gemma**, RL, Vision, exporta√ß√£o GGUF e deployment em produ√ß√£o. <br>
>  <br>
>  

<br><br><br>



## Ind√≠ce

- [Introdu√ß√£o](#introdu√ß√£o)
- [Features](#features)
- [Instala√ß√£o](#instala√ß√£o)
  - [Pip](#pip)
  - [Conda](#conda)
  - [Docker](#docker)
  - [Windows](#windows)
  - [Google Colab](#google-colab)
- [Guia de Fine-tuning](#guia-de-fine-tuning)
  - [Escolha de Modelo](#escolha-de-modelo)
  - [Estrutura de Dataset](#estrutura-de-dataset)
  - [Hiperpar√¢metros LoRA](#hiperpar√¢metros-lora)
  - [Vision Fine-tuning](#vision-fine-tuning)
- [Ministral-3 Quickstart](#ministral-3-quickstart)
- [Notebooks](#notebooks)
- [Scripts](#scripts)
- [Estrutura do Reposit√≥rio](#estrutura-do-reposit√≥rio)
- [Deployment & Export](#deployment--export)
  - [Ollama](#ollama)
  - [vLLM](#vllm)
  - [GGUF](#gguf)
- [Troubleshooting](#troubleshooting)
- [Comunidade & Suporte](#comunidade--suporte)
- [License](#license)



  <br><br>



## [Introdu√ß√£o]()

Este reposit√≥rio consolida um ambiente robusto e padronizado para:
Fine-tuning eficiente com LoRA/QLoRA
Reinforcement Learning (GRPO, DPO, ORPO, KTO)
Treinamento de vis√£o (VLMs)
Exporta√ß√£o para GGUF e deploy em CPU/GPU
Infer√™ncia otimizada com Unsloth e vLLM
Ambiente de desenvolvimento reprodut√≠vel (Docker + Conda)
Suporte completo para:
Ministral-3 (todos os tamanhos)
Llama 3.x
Qwen 2.5 / 3 / VL
Gemma 3
DeepSeek V3 / R1
Phi 3
Vision LLMs





